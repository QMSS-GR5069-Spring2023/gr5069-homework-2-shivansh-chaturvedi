{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOOrA6PiV5Zw"
   },
   "source": [
    "Shivansh Chaturvedi\n",
    "GR5073 - Midterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBdeUAZqVO-T",
    "outputId": "f0fad3f2-b80d-41b3-9f67-31c76d80f7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpxjOac9XHta"
   },
   "source": [
    "#### (1) Import the spam dataset and print the first six rows.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "Blq_JSewXBcM",
    "outputId": "69306be3-73bc-41fa-f545-49c9d0845f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-41b7dfc9-5a7f-43ab-8389-d1deb932f795\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make:</th>\n",
       "      <th>word_freq_address:</th>\n",
       "      <th>word_freq_all:</th>\n",
       "      <th>word_freq_3d:</th>\n",
       "      <th>word_freq_our:</th>\n",
       "      <th>word_freq_over:</th>\n",
       "      <th>word_freq_remove:</th>\n",
       "      <th>word_freq_internet:</th>\n",
       "      <th>word_freq_order:</th>\n",
       "      <th>word_freq_mail:</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;:</th>\n",
       "      <th>char_freq_(:</th>\n",
       "      <th>char_freq_[:</th>\n",
       "      <th>char_freq_!:</th>\n",
       "      <th>char_freq_$:</th>\n",
       "      <th>char_freq_#:</th>\n",
       "      <th>capital_run_length_average:</th>\n",
       "      <th>capital_run_length_longest:</th>\n",
       "      <th>capital_run_length_total:</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 58 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41b7dfc9-5a7f-43ab-8389-d1deb932f795')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-41b7dfc9-5a7f-43ab-8389-d1deb932f795 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-41b7dfc9-5a7f-43ab-8389-d1deb932f795');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
       "0             0.00                0.64            0.64            0.0   \n",
       "1             0.21                0.28            0.50            0.0   \n",
       "2             0.06                0.00            0.71            0.0   \n",
       "3             0.00                0.00            0.00            0.0   \n",
       "4             0.00                0.00            0.00            0.0   \n",
       "5             0.00                0.00            0.00            0.0   \n",
       "\n",
       "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
       "0            0.32             0.00               0.00                 0.00   \n",
       "1            0.14             0.28               0.21                 0.07   \n",
       "2            1.23             0.19               0.19                 0.12   \n",
       "3            0.63             0.00               0.31                 0.63   \n",
       "4            0.63             0.00               0.31                 0.63   \n",
       "5            1.85             0.00               0.00                 1.85   \n",
       "\n",
       "   word_freq_order:  word_freq_mail:  ...  char_freq_;:  char_freq_(:  \\\n",
       "0              0.00             0.00  ...          0.00         0.000   \n",
       "1              0.00             0.94  ...          0.00         0.132   \n",
       "2              0.64             0.25  ...          0.01         0.143   \n",
       "3              0.31             0.63  ...          0.00         0.137   \n",
       "4              0.31             0.63  ...          0.00         0.135   \n",
       "5              0.00             0.00  ...          0.00         0.223   \n",
       "\n",
       "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
       "0           0.0         0.778         0.000         0.000   \n",
       "1           0.0         0.372         0.180         0.048   \n",
       "2           0.0         0.276         0.184         0.010   \n",
       "3           0.0         0.137         0.000         0.000   \n",
       "4           0.0         0.135         0.000         0.000   \n",
       "5           0.0         0.000         0.000         0.000   \n",
       "\n",
       "   capital_run_length_average:  capital_run_length_longest:  \\\n",
       "0                        3.756                           61   \n",
       "1                        5.114                          101   \n",
       "2                        9.821                          485   \n",
       "3                        3.537                           40   \n",
       "4                        3.537                           40   \n",
       "5                        3.000                           15   \n",
       "\n",
       "   capital_run_length_total:  spam  \n",
       "0                        278     1  \n",
       "1                       1028     1  \n",
       "2                       2259     1  \n",
       "3                        191     1  \n",
       "4                        191     1  \n",
       "5                         54     1  \n",
       "\n",
       "[6 rows x 58 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#importing and reading\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Machine Learning/HW Midterms/spam_dataset.csv\")\n",
    "print(df.shape)\n",
    "df.head(n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzB7_ByCX0l5"
   },
   "source": [
    "#### (2) Read through the documentation of the original dataset here:\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\n",
    "\n",
    "The dependent variable is \"spam\" where one indicates that an email is spam and zero otherwise.  Which three variables in the dataset do you think will be important predictors in a model of spam?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-Z_ZhTVehnZ"
   },
   "source": [
    "I would guess that 3 important predictors would be:\n",
    "1. capital_run_length_average: Spam email often isn't well formatted and will be prone to run-on sentences with poor capitalization.\n",
    "2. word_freq_free: Spam email is also enticing for offering 'free' things, so this word frequency should capture such instances.\n",
    "3. word_freq_credit: Spam email could target those with poor credit scores offering to raise it, or will ask for credit card details, this should capture those"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9cv8Y_iZm8t"
   },
   "source": [
    "#### (3) Visualize the univariate distribution of each of the variables in the previous question.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "5bs8QQWUZpYz",
    "outputId": "ce4ec22a-cb52-41b7-8f26-bc8aaa5f8647"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# visualizing capital_run_length_average:\n",
    "df['capital_run_length_average:'].hist(range=[0, 15])\n",
    "plt.xlabel('Average Run On Length')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "foOoaO1Fbh2X",
    "outputId": "1319a6dd-5413-4321-d471-8f8a8d871a05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing word_freq_free:\n",
    "df['word_freq_free:'].hist(range=[0, 5], color='y')\n",
    "plt.xlabel(\"Frequency for the word 'Free'\")\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "9JN_zGWybljG",
    "outputId": "04952778-97d9-4666-fa4f-20076038b21a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing word_freq_credit:\n",
    "df['word_freq_credit:'].hist(range=[0, 1], color='g')\n",
    "plt.xlabel(\"Frequency for the word 'Credit'\")\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ3C18kndEJZ"
   },
   "source": [
    "#### (4) Name each of the supervised learning models that we have learned thus far that are used to predict dependent variables like \"spam\".   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pHGOFHzeLV2"
   },
   "source": [
    "We have covered K-Nearest Neighbor (Classifier), OneHotEncoders, Logistic Regression, Penalized Logistic Regression, Decision Trees Classifier, Random Forests Classifier (bagging, boosting), Support Vector Machines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jqcu07_cd8LK"
   },
   "source": [
    "#### (5) Describe the importance of training and test data.  Why do we separate data into these subsets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6q_OmiPeuIL"
   },
   "source": [
    "Splitting data is an important part of data science, as it helps make models more accurate. In machine learning, data can be split into test and training data. The training data is used to fit the model and train it to determine a prediction and to gain an understanding of the data. The test data set is then used to compare results of models. Splitting up the data to 'train' and 'test' can be used to prevent overfitting a model and to ensure that the model is able to generate results that are accurate and useful. A train-test split is an effective way to check is a model has learned the data and is able to use it to generate results; however, the model is only 'scored' or evaluated on the results of the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAI5qiwwg6N9"
   },
   "source": [
    "#### (6) What is k-fold cross validation and what do we use it for?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPvG2CKaiyfw"
   },
   "source": [
    "K-Fold cross-validation is the process of splitting up machine learning input data into \"k\" number of \"folds\" or groups; for example, when k=10, the data is split into 10 different groups. \n",
    "\n",
    "Cross-validation is a way to measure and evaluate machine learning models based on input data. In k-fold cross-validation, the test and training data and cycled through: in one iteration, a first section will be used as test data while the others will be used for training, and then scored. This process will continue through all the folds to get a good test and training score. By holding one section as test and running the k-1 sections as training, it is possible to get a better score and evaluation of the model, with reduced bias in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l7_g3i-kXgz"
   },
   "source": [
    "#### (7) How is k-fold cross validation different from stratified k-fold cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULM1yzILkoYp"
   },
   "source": [
    "Stratified K-Fold Cross Validation (SKFCV) is a slightly more advanced version of K-Fold Cross Validation (KFCV). In SKFCV, the above described splits in data (folds) will also retain certain properties of the whole dataset; for example, a percentage or proportion of observations with a specific kind of label or attribute. SKFCV is thus a little less random, but can be more accurate and can help improve models in some cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2zchRihxZZb"
   },
   "source": [
    "#### (8) Choose one model from question four.  Split the data into training and test subsets.  Build a model with the three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "zbgzHnTkxZHS"
   },
   "outputs": [],
   "source": [
    "# I will use KNN Classifier for this question\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# keeping only three variables + the dependent variable\n",
    "df2 = df[['capital_run_length_average:','word_freq_free:','word_freq_credit:','spam']]\n",
    "df2.head()\n",
    "\n",
    "# splitting data into y and x\n",
    "y = df2['spam']\n",
    "X = df2.loc[:, df2.columns != 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVA3QDOazFJQ",
    "outputId": "a76c0044-2999-43d7-c8ca-67d8ba14cc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 3)\n",
      "(3450, 3)\n",
      "(1151, 3)\n"
     ]
    }
   ],
   "source": [
    "# test train split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Scaling all the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88xPYS_RzWMx",
    "outputId": "f31ef5e4-3212-4689-cd70-bf1840251a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 11}\n"
     ]
    }
   ],
   "source": [
    "# using GridSearchCV to tune parameters for the model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# List a set of potential parameters\n",
    "knn_param_grid = {'n_neighbors': np.arange(1, 20, 2)}\n",
    "knngrid = GridSearchCV(KNeighborsClassifier(), param_grid=knn_param_grid)\n",
    "knngrid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: {}\".format(knngrid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHLFV0UpDxGh",
    "outputId": "59cc26e1-7bfa-468d-c0d3-dcb236d5526f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFER (SCALED) SCORES\n",
      "Test Set Score: 0.808\n",
      "Mean Cross Validation Score using KFold: 0.817\n",
      "\n",
      "\n",
      "I used GridSearchCV to decide on a specific value of K: this value came out to be n=11.\n"
     ]
    }
   ],
   "source": [
    "# importing cross val & mean for score calculations; KFold for kfold CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from statistics import mean \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y_train)\n",
    "kfold = KFold()\n",
    "\n",
    "print(\"KNN CLASSIFER (SCALED) SCORES\")\n",
    "print(\"Test Set Score: {:.3f}\".format(knn.score(X_test, y_test)))\n",
    "print(\"Mean Cross Validation Score using KFold: {:.3f}\".format(np.mean(cross_val_score(knn, X_train, y_train, cv=kfold))))\n",
    "knn_test_score = knn.score(X_test, y_test)\n",
    "knn_mean_score = np.mean(cross_val_score(knn, X_train, y_train, cv=kfold))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"I used GridSearchCV to decide on a specific value of K: this value came out to be n=11.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pek0ctHVErhi"
   },
   "source": [
    "#### (9) Choose a second model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4H7D04FEwlz",
    "outputId": "f9a3bf74-7fec-47b8-a827-7bf94e5e6ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 9}\n"
     ]
    }
   ],
   "source": [
    "# I will use random forest classifier for this question\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_param_grid = {'criterion':['gini','entropy'],'max_depth':np.arange(1, 10), 'n_estimators':np.arange(1, 10)}\n",
    "forestgrid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid=forest_param_grid)\n",
    "forestgrid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: {}\".format(forestgrid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ChDP6APBwvbJ",
    "outputId": "061fbbb6-3fc6-43b3-b7cd-10dabea1ebf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST (SCALED) SCORES\n",
      "Test set score: 0.810\n",
      "Mean Cross Validation Score using KFold: 0.826\n",
      "\n",
      "\n",
      "I used GridSearchCV to decide on some of the parameters for RandomForestClassifier (I did not do all possible parameters as it was computationally expensive) and found that.\n",
      "the best results were at 'criterion': 'gini', 'max_depth': 6, 'n_estimators': 9\n",
      "\n",
      "\n",
      "Other Model Results So Far\n",
      "KNN Test Set Score: 0.808\n",
      "KNN Mean CV Score: 0.817\n",
      "\n",
      "\n",
      "The Random Forest model was better than the KNNClassifier Model for both Mean Score and Test Score.\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(criterion = 'gini', max_depth = 6, n_estimators = 9, random_state=42)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "print(\"RANDOM FOREST (SCALED) SCORES\")\n",
    "print(\"Test set score: {:.3f}\".format(forest.score(X_test, y_test)))\n",
    "print(\"Mean Cross Validation Score using KFold: {:.3f}\".format(np.mean(cross_val_score(forest, X_train, y_train, cv=kfold))))\n",
    "forest_test_score = forest.score(X_test, y_test)\n",
    "forest_mean_score = np.mean(cross_val_score(forest, X_train, y_train, cv=kfold))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"I used GridSearchCV to decide on some of the parameters for RandomForestClassifier (I did not do all possible parameters as it was computationally expensive) and found that.\")\n",
    "print(\"the best results were at 'criterion': 'gini', 'max_depth': 6, 'n_estimators': 9\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Other Model Results So Far\")\n",
    "print(\"KNN Test Set Score: {:.3f}\".format(knn_test_score))\n",
    "print(\"KNN Mean CV Score: {:.3f}\".format(knn_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"The Random Forest model was better than the KNNClassifier Model for both Mean Score and Test Score.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAMSS2tSXMCw"
   },
   "source": [
    "#### (10) Choose a third model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8scXh8AXKzL",
    "outputId": "830f9961-69f4-4e20-e71a-db6e5b10dab7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100}\n"
     ]
    }
   ],
   "source": [
    "# I will use logistic regression for this question\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "logreggrid = GridSearchCV(LogisticRegression(random_state=42), param_grid=logreg_param_grid)\n",
    "logreggrid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: {}\".format(logreggrid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFnXKtZjZGQz",
    "outputId": "0e2165cf-b54a-4d3b-cd41-64f5cc0284f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION (SCALED) SCORES\n",
      "Test set score: 0.770\n",
      "Mean Cross Validation Score using KFold: 0.775\n",
      "\n",
      "\n",
      "I used GridSearchCV to find that the best C value for an unpenalized Logistic Regression is C=100\n",
      "\n",
      "\n",
      "Other Model Results So Far\n",
      "KNN Test Set Score: 0.808\n",
      "KNN Mean CV Score: 0.817\n",
      "Forest Test Set Score: 0.810\n",
      "Forest Mean CV Score: 0.826\n",
      "\n",
      "\n",
      "The Logistic Regression model was not better than the Random Forest Model or than the KNN Classifier Model.\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty = 'none', C=100, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (SCALED) SCORES\")\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
    "print(\"Mean Cross Validation Score using KFold: {:.3f}\".format(np.mean(cross_val_score(logreg, X_train, y_train, cv=kfold))))\n",
    "logreg_test_score = logreg.score(X_test, y_test)\n",
    "logreg_mean_score = np.mean(cross_val_score(logreg, X_train, y_train, cv=kfold))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"I used GridSearchCV to find that the best C value for an unpenalized Logistic Regression is C=100\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Other Model Results So Far\")\n",
    "print(\"KNN Test Set Score: {:.3f}\".format(knn_test_score))\n",
    "print(\"KNN Mean CV Score: {:.3f}\".format(knn_mean_score))\n",
    "print(\"Forest Test Set Score: {:.3f}\".format(forest_test_score))\n",
    "print(\"Forest Mean CV Score: {:.3f}\".format(forest_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"The Logistic Regression model was not better than the Random Forest Model or than the KNN Classifier Model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFY41emKa91N"
   },
   "source": [
    "#### (11) Choose a fourth model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOMKoXN9bCh_",
    "outputId": "c5b9abb5-1d8b-4a98-ed7b-b95e8647b6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 8, 'min_samples_leaf': 7}\n"
     ]
    }
   ],
   "source": [
    "# I will use Decision Tree Classifier for this question\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_param_grid = {'criterion':['gini','entropy'],'max_depth': np.arange(1, 10), 'min_samples_leaf':np.arange(1,10)}\n",
    "treegrid = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid=tree_param_grid)\n",
    "treegrid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters: {}\".format(treegrid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Da8vvlmRdv-8",
    "outputId": "b1c7b03b-c803-4184-bc6b-267d01a98ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE MODEL (SCALED) SCORES\n",
      "Test set score: 0.802\n",
      "Mean Cross Validation Score using KFold: 0.815\n",
      "\n",
      "\n",
      "I used GridSearchCV to find that the best parameters for this Tree Model are 'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 7\n",
      "\n",
      "\n",
      "Other Model Results So Far\n",
      "KNN Test Set Score: 0.808\n",
      "KNN Mean CV Score: 0.817\n",
      "Forest Test Set Score: 0.810\n",
      "Forest Mean CV Score: 0.826\n",
      "Logistic Regression Test Set Score: 0.770\n",
      "Logistic Regression Mean CV Score: 0.775\n",
      "\n",
      "\n",
      "The Tree Model was better than the Logistic Regression.\n",
      "It was, however, not better than the Random Forest Model and KNN Classifier Model.\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion = 'gini', max_depth = 8, min_samples_leaf = 7, random_state=42)\n",
    "tree.fit(X_train,y_train)\n",
    "\n",
    "print(\"TREE MODEL (SCALED) SCORES\")\n",
    "print(\"Test set score: {:.3f}\".format(tree.score(X_test, y_test)))\n",
    "print(\"Mean Cross Validation Score using KFold: {:.3f}\".format(np.mean(cross_val_score(tree, X_train, y_train, cv=kfold))))\n",
    "tree_test_score = tree.score(X_test, y_test)\n",
    "tree_mean_score = np.mean(cross_val_score(tree, X_train, y_train, cv=kfold))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"I used GridSearchCV to find that the best parameters for this Tree Model are 'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 7\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Other Model Results So Far\")\n",
    "print(\"KNN Test Set Score: {:.3f}\".format(knn_test_score))\n",
    "print(\"KNN Mean CV Score: {:.3f}\".format(knn_mean_score))\n",
    "print(\"Forest Test Set Score: {:.3f}\".format(forest_test_score))\n",
    "print(\"Forest Mean CV Score: {:.3f}\".format(forest_mean_score))\n",
    "print(\"Logistic Regression Test Set Score: {:.3f}\".format(logreg_test_score))\n",
    "print(\"Logistic Regression Mean CV Score: {:.3f}\".format(logreg_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"The Tree Model was better than the Logistic Regression.\") \n",
    "print(\"It was, however, not better than the Random Forest Model and KNN Classifier Model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR97RXCQgwOM"
   },
   "source": [
    "#### (12) Now rerun your best model from questions 8 through 11, but this time add three new variables to the model that you think will increase prediction accuracy.   Did this model predict test data better than your previous models?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "id": "R22-tSYagyOo"
   },
   "outputs": [],
   "source": [
    "# I will use Random Forest Classifier for this question, as it gave me the best Test Set Score above\n",
    "\n",
    "# having six variables total + the dependent variable (I added variables for 'receive', 'money' and '!')\n",
    "df3 = df[['capital_run_length_average:','word_freq_free:','word_freq_credit:', 'word_freq_receive:', 'word_freq_money:', 'char_freq_!:', 'spam']]\n",
    "\n",
    "# splitting data into y and x\n",
    "y2 = df3['spam']\n",
    "X2 = df3.loc[:, df3.columns != 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "id": "LiIweqOQh8KM"
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train2)\n",
    "X_train2 = scaler.transform(X_train2)\n",
    "X_test2 = scaler.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UBEcRDUiLmo",
    "outputId": "f3c090e1-3d51-46b1-898b-c066669597cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST (SCALED) SCORES WITH 6 VARIABLES\n",
      "Test set score: 0.892\n",
      "Mean Cross Validation Score using KFold: 0.872\n",
      "\n",
      "\n",
      "RESULTS FOR MODELS WITH 3 VARIABLES\n",
      "KNN Test Set Score: 0.808\n",
      "KNN Mean CV Score: 0.817\n",
      "Forest Test Set Score: 0.810\n",
      "Forest Mean CV Score: 0.826\n",
      "Logistic Regression Test Set Score: 0.770\n",
      "Logistic Regression Mean CV Score: 0.775\n",
      "Tree Test Set Score: 0.802\n",
      "Tree Mean CV Score: 0.815\n",
      "\n",
      "\n",
      "This new Random Forest model with 6 variables was a better predictor of test data than all the models before.\n"
     ]
    }
   ],
   "source": [
    "forest.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"RANDOM FOREST (SCALED) SCORES WITH 6 VARIABLES\")\n",
    "print(\"Test set score: {:.3f}\".format(forest.score(X_test2, y_test2)))\n",
    "print(\"Mean Cross Validation Score using KFold: {:.3f}\".format(np.mean(cross_val_score(forest, X_train2, y_train2, cv=kfold))))\n",
    "forest2_test_score = forest.score(X_test2, y_test2)\n",
    "forest2_mean_score = np.mean(cross_val_score(forest, X_train2, y_train2, cv=kfold))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RESULTS FOR MODELS WITH 3 VARIABLES\")\n",
    "print(\"KNN Test Set Score: {:.3f}\".format(knn_test_score))\n",
    "print(\"KNN Mean CV Score: {:.3f}\".format(knn_mean_score))\n",
    "print(\"Forest Test Set Score: {:.3f}\".format(forest_test_score))\n",
    "print(\"Forest Mean CV Score: {:.3f}\".format(forest_mean_score))\n",
    "print(\"Logistic Regression Test Set Score: {:.3f}\".format(logreg_test_score))\n",
    "print(\"Logistic Regression Mean CV Score: {:.3f}\".format(logreg_mean_score))\n",
    "print(\"Tree Test Set Score: {:.3f}\".format(tree_test_score))\n",
    "print(\"Tree Mean CV Score: {:.3f}\".format(tree_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"This new Random Forest model with 6 variables was a better predictor of test data than all the models before.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3bWOj7ykW9a"
   },
   "source": [
    "#### (13) Rerun all your other models with this final set of six variables, evaluate prediction error, and choose a final model.  Why did you select this model among all of the models that you ran?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmwdSPEHkWtt",
    "outputId": "ab382a56-29cb-4034-8956-d4b9e976249f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFER (SCALED) SCORES\n",
      "Test Set Score with 6 variables: 0.862\n",
      "Mean Cross Validation Score using KFold with 6 variables: 0.860\n",
      "Test Set Score with 3 variables: 0.808\n",
      "Mean Cross Validation Score using KFold with 3 variables: 0.817\n",
      "\n",
      "\n",
      "LOGISTIC REGRESSION (SCALED) SCORES\n",
      "Test Set Score with 6 variables: 0.823\n",
      "Mean Cross Validation Score using KFold with 6 variables: 0.818\n",
      "Test Set Score with 3 variables: 0.770\n",
      "Mean Cross Validation Score using KFold with 3 variables: 0.775\n",
      "\n",
      "\n",
      "TREE MODEL (SCALED) SCORES\n",
      "Test Set Score with 6 variables: 0.878\n",
      "Mean Cross Validation Score using KFold with 6 variables: 0.858\n",
      "Test Set Score with 3 variables: 0.802\n",
      "Mean Cross Validation Score using KFold with 3 variables: 0.815\n",
      "\n",
      "\n",
      "RANDOM FOREST (SCALED) SCORES\n",
      "Test set score with 6 variables: 0.892\n",
      "Mean Cross Validation Score using KFold with 6 variables: 0.872\n",
      "Test set score with 3 variables: 0.810\n",
      "Mean Cross Validation Score using KFold with 3 variables: 0.826\n",
      "\n",
      "\n",
      "Based on the scores above, as well as the scores from the previous question, the Random Forest Model with 6 Variables\n",
      "had the highest test score and the highest Mean Cross Val of all the models presented so far (in this random state). \n",
      "Based on this performance, I would choose this model, as it is the best predictor of unseen data. \n"
     ]
    }
   ],
   "source": [
    "# K Neighbors Classifier\n",
    "\n",
    "knn.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"KNN CLASSIFER (SCALED) SCORES\")\n",
    "print(\"Test Set Score with 6 variables: {:.3f}\".format(knn.score(X_test2, y_test2)))\n",
    "print(\"Mean Cross Validation Score using KFold with 6 variables: {:.3f}\".format(np.mean(cross_val_score(knn, X_train2, y_train2, cv=kfold))))\n",
    "print(\"Test Set Score with 3 variables: {:.3f}\".format(knn_test_score))\n",
    "print(\"Mean Cross Validation Score using KFold with 3 variables: {:.3f}\".format(knn_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "logreg.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"LOGISTIC REGRESSION (SCALED) SCORES\")\n",
    "print(\"Test Set Score with 6 variables: {:.3f}\".format(logreg.score(X_test2, y_test2)))\n",
    "print(\"Mean Cross Validation Score using KFold with 6 variables: {:.3f}\".format(np.mean(cross_val_score(logreg, X_train2, y_train2, cv=kfold))))\n",
    "print(\"Test Set Score with 3 variables: {:.3f}\".format(logreg_test_score))\n",
    "print(\"Mean Cross Validation Score using KFold with 3 variables: {:.3f}\".format(logreg_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Tree\n",
    "\n",
    "tree.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"TREE MODEL (SCALED) SCORES\")\n",
    "print(\"Test Set Score with 6 variables: {:.3f}\".format(tree.score(X_test2, y_test2)))\n",
    "print(\"Mean Cross Validation Score using KFold with 6 variables: {:.3f}\".format(np.mean(cross_val_score(tree, X_train2, y_train2, cv=kfold))))\n",
    "print(\"Test Set Score with 3 variables: {:.3f}\".format(tree_test_score))\n",
    "print(\"Mean Cross Validation Score using KFold with 3 variables: {:.3f}\".format(tree_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RANDOM FOREST (SCALED) SCORES\")\n",
    "print(\"Test set score with 6 variables: {:.3f}\".format(forest2_test_score))\n",
    "print(\"Mean Cross Validation Score using KFold with 6 variables: {:.3f}\".format(forest2_mean_score))\n",
    "print(\"Test set score with 3 variables: {:.3f}\".format(forest_test_score))\n",
    "print(\"Mean Cross Validation Score using KFold with 3 variables: {:.3f}\".format(forest_mean_score))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Summarizing\n",
    "\n",
    "print(\"Based on the scores above, as well as the scores from the previous question, the Random Forest Model with 6 Variables\")\n",
    "print(\"had the highest test score and the highest Mean Cross Val of all the models presented so far (in this random state). \")\n",
    "print(\"Based on this performance, I would choose this model, as it is the best predictor of unseen data. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oKPn8mHro3w"
   },
   "source": [
    "#### (14) What variable that currently is not in your model, if included, would be likely to increase your final model's predictive power?  For this answer try to speculate about a variable outside the variables available in the data that would improve you model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QFvxOjurrT3"
   },
   "source": [
    "I would have loved to see a variable counting for words like \"click here\", as I know that many spam emails use clickbait as a way to extract personal information. \n",
    "\n",
    "I also think that a variable that counts the number of hyperlinks/URLs in the e-mail body would be cool, as it would be a good indicator to see how many outbound routes that email presents (which is also a popular aspect of spam emails, especially advertising or deal spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z_QL48VsTuE"
   },
   "source": [
    "#### (15) Lastly, you have listed each of the models that we have learned to use to predict dependent variables like spam.  List each model we have focused on in class thus far that you could use to evaluate data with a continuous dependent variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0TuQaULsoVO"
   },
   "source": [
    "We have covered K-Nearest Neighbor (Regressor), Linear Regression, Ridge, Lasso, Logistic Regression, Decision Trees Regressor, Random Forests Regressor, (bagging, boosting), Support Vector Machines"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
